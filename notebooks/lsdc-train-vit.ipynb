{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77778fc1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-16T08:10:52.387321Z",
     "iopub.status.busy": "2024-09-16T08:10:52.386555Z",
     "iopub.status.idle": "2024-09-16T08:13:15.294877Z",
     "shell.execute_reply": "2024-09-16T08:13:15.293695Z"
    },
    "papermill": {
     "duration": 142.929474,
     "end_time": "2024-09-16T08:13:15.306168",
     "exception": false,
     "start_time": "2024-09-16T08:10:52.376694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.8.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet /kaggle/input/timm_3d_deps/other/initial/10/pydicom/pydicom/pydicom-2.4.4-py3-none-any.whl\n",
    "%pip install timm_3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/timm_3d/\n",
    "%pip install torchio --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/torchio/\n",
    "%pip install itk --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/itk/itk\n",
    "%pip install skorch --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/skorch/skorch\n",
    "%pip install spacecutter --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/spacecutter/\n",
    "%pip install open3d --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/open3d\n",
    "%pip install pgzip --no-index --quiet --find-links=/kaggle/input/timm_3d_deps/other/initial/10/pgzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b6a60d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:15.345016Z",
     "iopub.status.busy": "2024-09-16T08:13:15.344664Z",
     "iopub.status.idle": "2024-09-16T08:13:15.349421Z",
     "shell.execute_reply": "2024-09-16T08:13:15.348616Z"
    },
    "papermill": {
     "duration": 0.017359,
     "end_time": "2024-09-16T08:13:15.351416",
     "exception": false,
     "start_time": "2024-09-16T08:13:15.334057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d614835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:15.371020Z",
     "iopub.status.busy": "2024-09-16T08:13:15.370729Z",
     "iopub.status.idle": "2024-09-16T08:13:18.644137Z",
     "shell.execute_reply": "2024-09-16T08:13:18.643316Z"
    },
    "papermill": {
     "duration": 3.285814,
     "end_time": "2024-09-16T08:13:18.646522",
     "exception": false,
     "start_time": "2024-09-16T08:13:15.360708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "CONFIG = dict(\n",
    "    n_levels=5,\n",
    "    num_classes=25,\n",
    "    num_conditions=5,\n",
    "    image_interpolation='nearest',\n",
    "    backbone='maxvit_rmlp_tiny_rw_256',\n",
    "    vol_size=(256, 256, 256),\n",
    "    vol_size=(64, 64, 64),\n",
    "    num_workers=4,\n",
    "    gradient_acc_steps=1,\n",
    "    drop_rate=0.4,\n",
    "    drop_rate_last=0.,\n",
    "    drop_path_rate=0.4,\n",
    "    aug_prob=0.9,\n",
    "    out_dim=3,\n",
    "    epochs=40,\n",
    "    batch_size=16,\n",
    "    split_k=5,\n",
    "    device=torch.device('cuda') if torch.cuda.is_available() else 'cpu',\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c713bae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:18.666912Z",
     "iopub.status.busy": "2024-09-16T08:13:18.666507Z",
     "iopub.status.idle": "2024-09-16T08:13:18.671354Z",
     "shell.execute_reply": "2024-09-16T08:13:18.670522Z"
    },
    "papermill": {
     "duration": 0.016869,
     "end_time": "2024-09-16T08:13:18.673122",
     "exception": false,
     "start_time": "2024-09-16T08:13:18.656253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONDITIONS = {\n",
    "    'Sagittal T2/STIR': ['Spinal Canal Stenosis'],\n",
    "    'Axial T2': ['Left Subarticular Stenosis', 'Right Subarticular Stenosis'],\n",
    "    'Sagittal T1': ['Left Neural Foraminal Narrowing', 'Right Neural Foraminal Narrowing'],\n",
    "}\n",
    "\n",
    "LABEL_MAP = {'normal_mild': 0, 'moderate': 1, 'severe': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2dfe98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:18.731198Z",
     "iopub.status.busy": "2024-09-16T08:13:18.730890Z",
     "iopub.status.idle": "2024-09-16T08:13:18.744875Z",
     "shell.execute_reply": "2024-09-16T08:13:18.744028Z"
    },
    "papermill": {
     "duration": 0.026281,
     "end_time": "2024-09-16T08:13:18.746759",
     "exception": false,
     "start_time": "2024-09-16T08:13:18.720478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_coordinate_training_data(train_path):\n",
    "    def reshape_row(row):\n",
    "        data = {'study_id': [], 'condition': [], 'level': [], 'severity': []}\n",
    "\n",
    "        for column, value in row.items():\n",
    "            if column not in ['study_id', 'series_id', 'instance_number', 'x', 'y', 'series_description']:\n",
    "                parts = column.split('_')\n",
    "                condition = ' '.join([word.capitalize() for word in parts[:-2]])\n",
    "                level = parts[-2].capitalize() + '/' + parts[-1].capitalize()\n",
    "                data['study_id'].append(row['study_id'])\n",
    "                data['condition'].append(condition)\n",
    "                data['level'].append(level)\n",
    "                data['severity'].append(value)\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    train = pd.read_csv(train_path + 'train.csv')\n",
    "    label = pd.read_csv(train_path + 'train_label_coordinates.csv')\n",
    "    train_desc = pd.read_csv(train_path + 'train_series_descriptions.csv')\n",
    "    test_desc = pd.read_csv(train_path + 'test_series_descriptions.csv')\n",
    "    sub = pd.read_csv(train_path + 'sample_submission.csv')\n",
    "\n",
    "    new_train_df = pd.concat([reshape_row(row) for _, row in train.iterrows()], ignore_index=True)\n",
    "    merged_df = pd.merge(new_train_df, label, on=['study_id', 'condition', 'level'], how='inner')\n",
    "    final_merged_df = pd.merge(merged_df, train_desc, on=['series_id', 'study_id'], how='inner')\n",
    "    final_merged_df['severity'] = final_merged_df['severity'].map(\n",
    "        {'Normal/Mild': 'normal_mild', 'Moderate': 'moderate', 'Severe': 'severe'})\n",
    "\n",
    "    final_merged_df['row_id'] = (\n",
    "        final_merged_df['study_id'].astype(str) + '_' +\n",
    "        final_merged_df['condition'].str.lower().str.replace(' ', '_') + '_' +\n",
    "        final_merged_df['level'].str.lower().str.replace('/', '_')\n",
    "    )\n",
    "\n",
    "    final_merged_df['image_path'] = (\n",
    "        f'{train_path}/train_images/' +\n",
    "        final_merged_df['study_id'].astype(str) + '/' +\n",
    "        final_merged_df['series_id'].astype(str) + '/' +\n",
    "        final_merged_df['instance_number'].astype(str) + '.dcm'\n",
    "    )\n",
    "\n",
    "    return final_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79aefdb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:18.766441Z",
     "iopub.status.busy": "2024-09-16T08:13:18.766160Z",
     "iopub.status.idle": "2024-09-16T08:13:21.375033Z",
     "shell.execute_reply": "2024-09-16T08:13:21.373994Z"
    },
    "papermill": {
     "duration": 2.621575,
     "end_time": "2024-09-16T08:13:21.377600",
     "exception": false,
     "start_time": "2024-09-16T08:13:18.756025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = retrieve_coordinate_training_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086cbde0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:21.417115Z",
     "iopub.status.busy": "2024-09-16T08:13:21.416444Z",
     "iopub.status.idle": "2024-09-16T08:13:21.437204Z",
     "shell.execute_reply": "2024-09-16T08:13:21.436276Z"
    },
    "papermill": {
     "duration": 0.033413,
     "end_time": "2024-09-16T08:13:21.439299",
     "exception": false,
     "start_time": "2024-09-16T08:13:21.405886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class StudyLevelDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 base_path: str,\n",
    "                 dataframe: pd.DataFrame,\n",
    "                 transform_3d=None,\n",
    "                 is_train=False,\n",
    "                 vol_size=(192, 192, 192),\n",
    "                 use_mirror_trick=False):\n",
    "        self.base_path = base_path\n",
    "        self.is_train = is_train\n",
    "        self.use_mirror_trick = use_mirror_trick\n",
    "\n",
    "        self.dataframe = (dataframe[['study_id', \"series_id\", \"series_description\", \"condition\", \"severity\", \"level\"]]\n",
    "                          .drop_duplicates())\n",
    "\n",
    "        self.subjects = self.dataframe[['study_id']].drop_duplicates().reset_index(drop=True)\n",
    "        self.series = self.dataframe[['study_id', 'series_id']].drop_duplicates().groupby('study_id')[\n",
    "            \"series_id\"].apply(list).to_dict()\n",
    "        self.series_descs = {e[0]: e[1] for e in\n",
    "                             self.dataframe[['series_id', 'series_description']].drop_duplicates().values}\n",
    "\n",
    "        self.transform_3d = transform_3d\n",
    "\n",
    "        self.levels = sorted(self.dataframe['level'].unique())\n",
    "        self.labels = self._get_labels()\n",
    "        self.vol_size = vol_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subjects) * (2 if self.use_mirror_trick else 1)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        is_mirror = index >= len(self.subjects)\n",
    "        curr = self.subjects.iloc[index % len(self.subjects)]\n",
    "\n",
    "        label = np.array(self.labels[(curr['study_id'])])\n",
    "        study_path = os.path.join(self.base_path, str(curr['study_id']))\n",
    "\n",
    "        study_images = read_study_as_voxel_grid_v2(study_path,\n",
    "                                                   curr['study_id'],\n",
    "                                                   series_type_dict=self.series_descs,\n",
    "                                                   img_size=(self.vol_size[0], self.vol_size[1]))\n",
    "\n",
    "        if is_mirror:\n",
    "            temp = label[:10].copy()\n",
    "            label[:10] = label[10:20].copy()\n",
    "            label[10:20] = temp\n",
    "\n",
    "        if self.transform_3d is not None:\n",
    "            study_images = torch.FloatTensor(study_images)\n",
    "\n",
    "            if is_mirror:\n",
    "                study_images = torch.flip(study_images, [1])\n",
    "\n",
    "            study_images = self.transform_3d(study_images)\n",
    "            return study_images.to(torch.half), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        print(\"loaded\")\n",
    "        return torch.HalfTensor(study_images.copy()), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def _get_labels(self):\n",
    "        labels = dict()\n",
    "        for name, group in self.dataframe.groupby(['study_id']):\n",
    "            group = group[['condition', 'level', 'severity']].drop_duplicates().sort_values(['condition', 'level'])\n",
    "            label_indices = []\n",
    "            for _, row in group.iterrows():\n",
    "                if row['severity'] in LABEL_MAP:\n",
    "                    label_indices.append(LABEL_MAP[row['severity']])\n",
    "                else:\n",
    "                    raise ValueError()\n",
    "\n",
    "            study_id = name[0]\n",
    "\n",
    "            labels[study_id] = label_indices\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b9f4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:21.477862Z",
     "iopub.status.busy": "2024-09-16T08:13:21.477522Z",
     "iopub.status.idle": "2024-09-16T08:13:21.506669Z",
     "shell.execute_reply": "2024-09-16T08:13:21.505939Z"
    },
    "papermill": {
     "duration": 0.041734,
     "end_time": "2024-09-16T08:13:21.508724",
     "exception": false,
     "start_time": "2024-09-16T08:13:21.466990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_study_as_voxel_grid_v2(dir_path,\n",
    "                                study_id,\n",
    "                                series_type_dict=None,\n",
    "                                downsampling_factor=1,\n",
    "                                img_size=(256, 256),\n",
    "                                caching=True,\n",
    "                                cache_base_path='/kaggle/working/3d_cache'):\n",
    "    if caching:\n",
    "        os.makedirs(os.path.join(cache_base_path, str(study_id)), exist_ok=True)\n",
    "        cache_path = os.path.join(cache_base_path, str(study_id), f'cached_grid_v2_{img_size[0]}.npy.gz')\n",
    "        f = None\n",
    "        if os.path.exists(cache_path):\n",
    "            try:\n",
    "                f = pgzip.PgzipFile(cache_path, 'r')\n",
    "                ret = np.load(f, allow_pickle=True)\n",
    "                f.close()\n",
    "                return ret\n",
    "            except Exception as e:\n",
    "                print(dir_path, '\\n', e)\n",
    "                if f:\n",
    "                    f.close()\n",
    "                os.remove(cache_path)\n",
    "\n",
    "    pcd_overall = read_study_as_pcd(dir_path,\n",
    "                                    series_types_dict=series_type_dict,\n",
    "                                    downsampling_factor=downsampling_factor,\n",
    "                                    img_size=img_size)\n",
    "    box = pcd_overall.get_axis_aligned_bounding_box()\n",
    "\n",
    "    max_b = np.array(box.get_max_bound())\n",
    "    min_b = np.array(box.get_min_bound())\n",
    "\n",
    "    pts = (np.array(pcd_overall.points) - (min_b)) * (\n",
    "        (img_size[0] - 1, img_size[0] - 1, img_size[0] - 1) / (max_b - min_b))\n",
    "    coords = np.round(pts).astype(np.int32)\n",
    "    vals = np.array(pcd_overall.colors, dtype=np.float16)\n",
    "\n",
    "    grid = np.zeros((3, img_size[0], img_size[0], img_size[0]), dtype=np.float16)\n",
    "    indices = coords[:, 0], coords[:, 1], coords[:, 2]\n",
    "\n",
    "    np.maximum.at(grid[0], indices, vals[:, 0])\n",
    "    np.maximum.at(grid[1], indices, vals[:, 1])\n",
    "    np.maximum.at(grid[2], indices, vals[:, 2])\n",
    "\n",
    "    if caching:\n",
    "        f = pgzip.PgzipFile(cache_path, \"w\")\n",
    "        np.save(f, grid)\n",
    "        f.close()\n",
    "\n",
    "    return grid\n",
    "\n",
    "def read_study_as_pcd(dir_path,\n",
    "                      series_types_dict=None,\n",
    "                      downsampling_factor=1,\n",
    "                      resize_slices=True,\n",
    "                      resize_method='nearest',\n",
    "                      stack_slices_thickness=True,\n",
    "                      img_size=(256, 256)):\n",
    "    pcd_overall = o3d.geometry.PointCloud()\n",
    "\n",
    "    for path in glob.glob(os.path.join(dir_path, '**/*.dcm'), recursive=True):\n",
    "        dicom_slice = dcmread(path)\n",
    "\n",
    "        series_id = os.path.basename(os.path.dirname(path))\n",
    "        study_id = os.path.basename(os.path.dirname(os.path.dirname(path)))\n",
    "        if series_types_dict is None or int(series_id) not in series_types_dict:\n",
    "            series_desc = dicom_slice.SeriesDescription\n",
    "        else:\n",
    "            series_desc = series_types_dict[int(series_id)]\n",
    "            series_desc = series_desc.split(\" \")[-1]\n",
    "\n",
    "        x_orig, y_orig = dicom_slice.pixel_array.shape\n",
    "        if resize_slices:\n",
    "            if resize_method == 'nearest':\n",
    "                img = np.expand_dims(cv2.resize(dicom_slice.pixel_array, img_size, interpolation=cv2.INTER_AREA), -1)\n",
    "            elif resize_method == 'maxpool':\n",
    "                img_tensor = torch.tensor(dicom_slice.pixel_array).float()\n",
    "                img = F.adaptive_max_pool2d(img_tensor.unsqueeze(0), img_size).numpy()\n",
    "            else:\n",
    "                raise ValueError(f'Invalid resize_method {resize_method}')\n",
    "        else:\n",
    "            img = np.expand_dims(np.array(dicom_slice.pixel_array), -1)\n",
    "        x, y, z = np.where(img)\n",
    "\n",
    "        downsampling_factor_iter = max(downsampling_factor, int(math.ceil(len(x) / 6e6)))\n",
    "\n",
    "        index_voxel = np.vstack((x, y, z))[:, ::downsampling_factor_iter]\n",
    "        grid_index_array = index_voxel.T\n",
    "        pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(grid_index_array.astype(np.float64)))\n",
    "\n",
    "        vals = np.expand_dims(img[x, y, z][::downsampling_factor_iter], -1)\n",
    "        if series_desc == 'T1':\n",
    "            vals = np.pad(vals, ((0, 0), (0, 2)))\n",
    "        elif series_desc == 'T2':\n",
    "            vals = np.pad(vals, ((0, 0), (1, 1)))\n",
    "        elif series_desc == 'T2/STIR':\n",
    "            vals = np.pad(vals, ((0, 0), (2, 0)))\n",
    "        else:\n",
    "            raise ValueError(f'Unknown series desc: {series_desc}')\n",
    "\n",
    "        pcd.colors = o3d.utility.Vector3dVector(vals.astype(np.float64))\n",
    "\n",
    "        if resize_slices:\n",
    "            transform_matrix_factor = np.matrix(\n",
    "                [[0, y_orig / img_size[1], 0, 0],\n",
    "                 [x_orig / img_size[0], 0, 0, 0],\n",
    "                 [0, 0, 1, 0],\n",
    "                 [0, 0, 0, 1]]\n",
    "            )\n",
    "        else:\n",
    "            transform_matrix_factor = np.matrix(\n",
    "                [[0, 1, 0, 0],\n",
    "                 [1, 0, 0, 0],\n",
    "                 [0, 0, 1, 0],\n",
    "                 [0, 0, 0, 1]]\n",
    "            )\n",
    "\n",
    "        dX, dY = dicom_slice.PixelSpacing\n",
    "        dZ = dicom_slice.SliceThickness\n",
    "\n",
    "        X = np.array(list(dicom_slice.ImageOrientationPatient[:3]) + [0]) * dX\n",
    "        Y = np.array(list(dicom_slice.ImageOrientationPatient[3:]) + [0]) * dY\n",
    "\n",
    "        S = np.array(list(dicom_slice.ImagePositionPatient) + [1])\n",
    "\n",
    "        transform_matrix = np.array([X, Y, np.zeros(len(X)), S]).T\n",
    "        transform_matrix = transform_matrix @ transform_matrix_factor\n",
    "\n",
    "        if stack_slices_thickness:\n",
    "            for z in range(int(dZ)):\n",
    "                pos = list(dicom_slice.ImagePositionPatient)\n",
    "                if series_desc == \"T2\":\n",
    "                    pos[-1] += z\n",
    "                else:\n",
    "                    pos[0] += z\n",
    "                S = np.array(pos + [1])\n",
    "\n",
    "                transform_matrix = np.array([X, Y, np.zeros(len(X)), S]).T\n",
    "                transform_matrix = transform_matrix @ transform_matrix_factor\n",
    "\n",
    "                pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n",
    "\n",
    "        else:\n",
    "            pcd_overall += copy.deepcopy(pcd).transform(transform_matrix)\n",
    "\n",
    "    return pcd_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d6cead",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:21.546891Z",
     "iopub.status.busy": "2024-09-16T08:13:21.546609Z",
     "iopub.status.idle": "2024-09-16T08:13:21.559022Z",
     "shell.execute_reply": "2024-09-16T08:13:21.558055Z"
    },
    "papermill": {
     "duration": 0.02473,
     "end_time": "2024-09-16T08:13:21.560902",
     "exception": false,
     "start_time": "2024-09-16T08:13:21.536172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_study_level_datasets_and_loaders_k_fold(df: pd.DataFrame,\n",
    "                                                   base_path: str,\n",
    "                                                   transform_3d_train=None,\n",
    "                                                   transform_3d_val=None,\n",
    "                                                   vol_size=None,\n",
    "                                                   split_k=5,\n",
    "                                                   random_seed=42,\n",
    "                                                   batch_size=1,\n",
    "                                                   num_workers=0,\n",
    "                                                   pin_memory=True,\n",
    "                                                   use_mirroring_trick=True):\n",
    "    df = df.dropna()\n",
    "\n",
    "    filtered_df = pd.DataFrame(columns=df.columns)\n",
    "    for series_desc in CONDITIONS.keys():\n",
    "        subset = df[df['series_description'] == series_desc]\n",
    "        if series_desc == 'Sagittal T2/STIR':\n",
    "            subset = subset[subset.groupby(['study_id']).transform('size') == 5]\n",
    "        else:\n",
    "            subset = subset[subset.groupby(['study_id']).transform('size') == 10]\n",
    "        filtered_df = pd.concat([filtered_df, subset])\n",
    "\n",
    "    filtered_df = filtered_df[filtered_df.groupby(['study_id']).transform('size') == 25]\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    ids = filtered_df['study_id'].unique()\n",
    "    np.random.shuffle(ids)\n",
    "\n",
    "    ret = []\n",
    "    folds = np.array_split(ids, split_k)\n",
    "\n",
    "    for _, fold in enumerate(folds):\n",
    "        val_studies = fold\n",
    "\n",
    "        train_df = filtered_df[~filtered_df['study_id'].isin(val_studies)]\n",
    "        val_df = filtered_df[filtered_df['study_id'].isin(val_studies)]\n",
    "\n",
    "        train_df = train_df.reset_index(drop=True)\n",
    "        val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "        train_dataset = StudyLevelDataset(base_path, train_df,\n",
    "                                          transform_3d=transform_3d_train,\n",
    "                                          is_train=True,\n",
    "                                          use_mirror_trick=use_mirroring_trick,\n",
    "                                          vol_size=vol_size\n",
    "                                          )\n",
    "        val_dataset = StudyLevelDataset(base_path, val_df,\n",
    "                                        transform_3d=transform_3d_val,\n",
    "                                        vol_size=vol_size\n",
    "                                        )\n",
    "\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=num_workers,\n",
    "                                  pin_memory=pin_memory,\n",
    "                                  persistent_workers=num_workers > 0)\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory,\n",
    "                                persistent_workers=num_workers > 0)\n",
    "\n",
    "        ret.append((train_loader, val_loader, train_dataset, val_dataset))\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4ebf18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:21.599013Z",
     "iopub.status.busy": "2024-09-16T08:13:21.598191Z",
     "iopub.status.idle": "2024-09-16T08:13:22.727717Z",
     "shell.execute_reply": "2024-09-16T08:13:22.726886Z"
    },
    "papermill": {
     "duration": 1.141931,
     "end_time": "2024-09-16T08:13:22.730065",
     "exception": false,
     "start_time": "2024-09-16T08:13:21.588134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "\n",
    "transform_3d_train = tio.Compose([\n",
    "    tio.ZNormalization(),\n",
    "    tio.RandomAffine(translation=10, p=CONFIG['aug_prob']),\n",
    "    tio.RandomNoise(p=CONFIG['aug_prob']),\n",
    "    tio.RandomSpike(1, intensity=(-0.5, 0.5), p=CONFIG['aug_prob']),\n",
    "    tio.RescaleIntensity((0, 1)),\n",
    "])\n",
    "\n",
    "transform_3d_val = tio.Compose([\n",
    "    tio.RescaleIntensity((0, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a131d087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:22.768866Z",
     "iopub.status.busy": "2024-09-16T08:13:22.767996Z",
     "iopub.status.idle": "2024-09-16T08:13:54.776406Z",
     "shell.execute_reply": "2024-09-16T08:13:54.775586Z"
    },
    "papermill": {
     "duration": 32.020879,
     "end_time": "2024-09-16T08:13:54.778765",
     "exception": false,
     "start_time": "2024-09-16T08:13:22.757886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1558759786.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  filtered_df = pd.concat([filtered_df, subset])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dataset_folds = create_study_level_datasets_and_loaders_k_fold(train_data,\n",
    "                                                               transform_3d_train=transform_3d_train,\n",
    "                                                               transform_3d_val=transform_3d_val,\n",
    "                                                               base_path=os.path.join(\n",
    "                                                                   data_path,\n",
    "                                                                   'train_images'),\n",
    "                                                               vol_size=CONFIG['vol_size'],\n",
    "                                                               num_workers=CONFIG['num_workers'],\n",
    "                                                               split_k=CONFIG['split_k'],\n",
    "                                                               batch_size=CONFIG['batch_size'],\n",
    "                                                               pin_memory=True,\n",
    "                                                               use_mirroring_trick=True\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3157fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:13:54.818077Z",
     "iopub.status.busy": "2024-09-16T08:13:54.817714Z",
     "iopub.status.idle": "2024-09-16T08:14:00.376151Z",
     "shell.execute_reply": "2024-09-16T08:14:00.375221Z"
    },
    "papermill": {
     "duration": 5.571128,
     "end_time": "2024-09-16T08:14:00.378323",
     "exception": false,
     "start_time": "2024-09-16T08:13:54.807195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pydicom import dcmread\n",
    "\n",
    "for index, fold in enumerate(dataset_folds):\n",
    "    trainloader, valloader, trainset, testset = fold\n",
    "\n",
    "    plt.imshow(np.mean(trainset[0][0].numpy()[0, 31:34], axis=0), cmap = \"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b4c7a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:14:00.419802Z",
     "iopub.status.busy": "2024-09-16T08:14:00.419261Z",
     "iopub.status.idle": "2024-09-16T08:14:03.104106Z",
     "shell.execute_reply": "2024-09-16T08:14:03.102979Z"
    },
    "papermill": {
     "duration": 2.699191,
     "end_time": "2024-09-16T08:14:03.107086",
     "exception": false,
     "start_time": "2024-09-16T08:14:00.407895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2848 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/357 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for fold in dataset_folds:\n",
    "    trainloader, valloader, trainset, testset = fold\n",
    "    \n",
    "    for train_point in tqdm(trainset):\n",
    "        pass\n",
    "        break\n",
    "    print('------------------')\n",
    "    for val_point in tqdm(testset):\n",
    "        pass\n",
    "        break\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1452b20",
   "metadata": {
    "papermill": {
     "duration": 0.010114,
     "end_time": "2024-09-16T08:14:03.128066",
     "exception": false,
     "start_time": "2024-09-16T08:14:03.117952",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6debc4fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:14:03.150505Z",
     "iopub.status.busy": "2024-09-16T08:14:03.150174Z",
     "iopub.status.idle": "2024-09-16T08:14:06.713599Z",
     "shell.execute_reply": "2024-09-16T08:14:06.712781Z"
    },
    "papermill": {
     "duration": 3.577679,
     "end_time": "2024-09-16T08:14:06.716083",
     "exception": false,
     "start_time": "2024-09-16T08:14:03.138404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm_3d\n",
    "import torch.nn as nn\n",
    "from spacecutter.losses import CumulativeLinkLoss\n",
    "from spacecutter.models import LogisticCumulativeLink\n",
    "from spacecutter.callbacks import AscensionCallback\n",
    "\n",
    "\n",
    "class Classifier3dMultihead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 backbone='efficientnet_lite0',\n",
    "                 in_chans=1,\n",
    "                 out_classes=5,\n",
    "                 cutpoint_margin=0.15,\n",
    "                 pretrained=False):\n",
    "        super(Classifier3dMultihead, self).__init__()\n",
    "        self.out_classes = out_classes\n",
    "\n",
    "        self.backbone = timm_3d.create_model(\n",
    "            backbone,\n",
    "            features_only=False,\n",
    "            drop_rate=CONFIG['drop_rate'],\n",
    "            drop_path_rate=CONFIG['drop_path_rate'],\n",
    "            pretrained=pretrained,\n",
    "            in_chans=in_chans,\n",
    "            global_pool='max',\n",
    "        )\n",
    "        if \"efficientnet\" in backbone:\n",
    "            head_in_dim = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Sequential(\n",
    "                nn.LayerNorm(head_in_dim),\n",
    "                nn.Dropout(CONFIG['drop_rate_last']),\n",
    "            )\n",
    "\n",
    "        elif \"vit\" in backbone:\n",
    "            self.backbone.head.drop = nn.Dropout(p=CONFIG['drop_rate_last'])\n",
    "            head_in_dim = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "\n",
    "        self.heads = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                nn.Linear(head_in_dim, 1),\n",
    "                LogisticCumulativeLink(CONFIG['out_dim'])\n",
    "            ) for i in range(out_classes)]\n",
    "        )\n",
    "\n",
    "        self.ascension_callback = AscensionCallback(margin=cutpoint_margin)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        return torch.swapaxes(torch.stack([head(feat) for head in self.heads]), 0, 1)\n",
    "\n",
    "    def _ascension_callback(self):\n",
    "        for head in self.heads:\n",
    "            self.ascension_callback.clip(head[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889456c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:14:06.780762Z",
     "iopub.status.busy": "2024-09-16T08:14:06.780379Z",
     "iopub.status.idle": "2024-09-16T08:14:06.814863Z",
     "shell.execute_reply": "2024-09-16T08:14:06.813892Z"
    },
    "papermill": {
     "duration": 0.048341,
     "end_time": "2024-09-16T08:14:06.816962",
     "exception": false,
     "start_time": "2024-09-16T08:14:06.768621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def model_validation_loss(model, val_loader, loss_fns, epoch):\n",
    "    val_loss = 0\n",
    "    unweighted_val_loss = 0\n",
    "    alt_val_loss = 0\n",
    "    unweighted_alt_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for images, label in tqdm(val_loader, desc=f'Validating epoch {epoch}'):\n",
    "            label = label.to(device).unsqueeze(-1)\n",
    "\n",
    "            with autocast(enabled=device != 'cpu', dtype=torch.bfloat16):\n",
    "                output = model(images.to(device))\n",
    "\n",
    "                for index, loss_fn in enumerate(loss_fns['train']):\n",
    "                    if len(loss_fns['train']) > 1:\n",
    "                        loss = loss_fn(output[:, index], label[:, index]) / len(loss_fns['train'])\n",
    "                    else:\n",
    "                        loss = loss_fn(output, label) / len(loss_fns['train'])\n",
    "                    val_loss += loss.cpu().item()\n",
    "\n",
    "                for index, loss_fn in enumerate(loss_fns['unweighted_val']):\n",
    "                    if len(loss_fns['unweighted_val']) > 1:\n",
    "                        loss = loss_fn(output[:, index], label[:, index]) / len(loss_fns['unweighted_val'])\n",
    "                    else:\n",
    "                        loss = loss_fn(output, label) / len(loss_fns['unweighted_val'])\n",
    "                    unweighted_val_loss += loss.cpu().item()\n",
    "\n",
    "                for index, loss_fn in enumerate(loss_fns[\"alt_val\"]):\n",
    "                    if len(loss_fns['alt_val']) > 1:\n",
    "                        loss = loss_fn(output[:, index], label.squeeze(-1)[:, index]) / len(loss_fns['alt_val'])\n",
    "                    else:\n",
    "                        loss = loss_fn(output, label) / len(loss_fns['alt_val'])\n",
    "                    alt_val_loss += loss.cpu().item()\n",
    "\n",
    "                for index, loss_fn in enumerate(loss_fns['unweighted_alt_val']):\n",
    "                    if len(loss_fns['unweighted_alt_val']) > 1:\n",
    "                        loss = loss_fn(output[:, index], label.squeeze(-1)[:, index]) / len(\n",
    "                            loss_fns['unweighted_alt_val'])\n",
    "                    else:\n",
    "                        loss = loss_fn(output, label) / len(loss_fns['alt_val'])\n",
    "                    unweighted_alt_val_loss += loss.cpu().item()\n",
    "\n",
    "                del output\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        unweighted_val_loss = unweighted_val_loss / len(val_loader)\n",
    "        alt_val_loss = alt_val_loss / len(val_loader)\n",
    "        unweighted_alt_val_loss = unweighted_alt_val_loss / len(val_loader)\n",
    "\n",
    "        return val_loss, unweighted_val_loss, alt_val_loss, unweighted_alt_val_loss\n",
    "\n",
    "def dump_plots_for_loss_and_acc(losses,\n",
    "                                val_losses,\n",
    "                                unweighted_val_losses,\n",
    "                                alt_val_losses,\n",
    "                                unweighted_alt_val_losses,\n",
    "                                data_subset_label,\n",
    "                                model_label):\n",
    "    plt.plot(np.log(losses), label='train')\n",
    "    plt.plot(np.log(val_losses), label='weighted_val')\n",
    "    plt.plot(np.log(unweighted_val_losses), label='unweighted_val')\n",
    "    plt.plot(np.log(alt_val_losses), label='alt_val')\n",
    "    plt.plot(np.log(unweighted_alt_val_losses), label='unweighted_alt_val')\n",
    "    plt.legend(loc='center right')\n",
    "    plt.title(data_subset_label)\n",
    "    plt.show()\n",
    "\n",
    "def train_model_with_validation(model,\n",
    "                                optimizers,\n",
    "                                schedulers,\n",
    "                                loss_fns,\n",
    "                                train_loader,\n",
    "                                val_loader,\n",
    "                                train_loader_desc=None,\n",
    "                                model_desc=\"my_model\",\n",
    "                                gradient_accumulation_per=1,\n",
    "                                epochs=10,\n",
    "                                freeze_backbone_initial_epochs=0,\n",
    "                                empty_cache_every_n_iterations=0,\n",
    "                                loss_weights=None,\n",
    "                                callbacks=None):\n",
    "    epoch_losses = []\n",
    "    epoch_validation_losses = []\n",
    "    epoch_unweighted_validation_losses = []\n",
    "    epoch_alt_validation_losses = []\n",
    "    epoch_unweighted_alt_validation_losses = []\n",
    "\n",
    "    scaler = GradScaler(init_scale=4096)\n",
    "\n",
    "    if freeze_backbone_initial_epochs > 0:\n",
    "        freeze_model_backbone(model)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=train_loader_desc):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        if freeze_backbone_initial_epochs > 0 and epoch == freeze_backbone_initial_epochs:\n",
    "            unfreeze_model_backbone(model)\n",
    "\n",
    "        for index, val in enumerate(tqdm(train_loader, desc=f'Epoch {epoch}')):\n",
    "            images, label = val\n",
    "            label = label.to(device).unsqueeze(-1)\n",
    "\n",
    "            with autocast(enabled=device != 'cpu', dtype=torch.bfloat16):\n",
    "                output = model(images.to(device))\n",
    "\n",
    "                del images\n",
    "\n",
    "                if len(loss_fns['train']) > 1:\n",
    "                    loss = sum([(loss_fn(output[:, loss_index], label[:, loss_index]) / gradient_accumulation_per) for\n",
    "                                loss_index, loss_fn in enumerate(loss_fns['train'])]) / len(loss_fns['train'])\n",
    "                else:\n",
    "                    loss = loss_fns['train'][0](output, label) / gradient_accumulation_per\n",
    "                epoch_loss += loss.detach().cpu().item() * gradient_accumulation_per\n",
    "\n",
    "                del label\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1e9)\n",
    "\n",
    "            del output\n",
    "\n",
    "            if index % gradient_accumulation_per == 0 or index == len(train_loader) - 1:\n",
    "                for optimizer in optimizers:\n",
    "                    scaler.step(optimizer)\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                scaler.update()\n",
    "\n",
    "            if callbacks:\n",
    "                for callback in callbacks:\n",
    "                    callback()\n",
    "\n",
    "            if empty_cache_every_n_iterations > 0 and index % empty_cache_every_n_iterations == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            while os.path.exists('.pause'):\n",
    "                pass\n",
    "\n",
    "        epoch_loss = epoch_loss / len(train_loader)\n",
    "        epoch_validation_loss, epoch_unweighted_validation_loss, epoch_alt_validation_loss, epoch_unweighted_alt_validation_loss = (\n",
    "            model_validation_loss(model, val_loader, loss_fns, epoch))\n",
    "\n",
    "        for scheduler in schedulers:\n",
    "            scheduler.step()\n",
    "\n",
    "        if (epoch % 5 == 0\n",
    "            or len(epoch_validation_losses) == 0\n",
    "            or epoch_validation_loss < min(epoch_validation_losses)) \\\n",
    "                or epoch_unweighted_validation_loss < min(epoch_unweighted_validation_losses) \\\n",
    "                or epoch_alt_validation_loss < min(epoch_alt_validation_losses):\n",
    "            os.makedirs(f'/kaggle/working/models/{model_desc}', exist_ok=True)\n",
    "            torch.save(model.state_dict(),\n",
    "                       f'/kaggle/working/models/{model_desc}/{model_desc}' + \"_\" + str(epoch) + '.pt')\n",
    "\n",
    "        epoch_validation_losses.append(epoch_validation_loss)\n",
    "        epoch_unweighted_validation_losses.append(epoch_unweighted_validation_loss)\n",
    "        epoch_alt_validation_losses.append(epoch_alt_validation_loss)\n",
    "        epoch_unweighted_alt_validation_losses.append(epoch_unweighted_alt_validation_loss)\n",
    "\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        dump_plots_for_loss_and_acc(epoch_losses,\n",
    "                                    epoch_validation_losses,\n",
    "                                    epoch_unweighted_validation_losses,\n",
    "                                    epoch_alt_validation_losses,\n",
    "                                    epoch_unweighted_alt_validation_losses,\n",
    "                                    train_loader_desc, model_desc)\n",
    "        print(f'Training Loss for epoch {epoch}: {epoch_loss:.6f}')\n",
    "        print(f'Validation Loss for epoch {epoch}: {epoch_validation_loss:.6f}')\n",
    "        print(f'Unweighted Validation Loss for epoch {epoch}: {epoch_unweighted_validation_loss:.6f}')\n",
    "        print(f'Alt Validation Loss for epoch {epoch}: {epoch_alt_validation_loss:.6f}')\n",
    "        print(f'Unweighted Alt Validation Loss for epoch {epoch}: {epoch_unweighted_alt_validation_loss:.6f}')\n",
    "\n",
    "    return epoch_losses, epoch_validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b8d959f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:14:06.861132Z",
     "iopub.status.busy": "2024-09-16T08:14:06.860799Z",
     "iopub.status.idle": "2024-09-16T08:14:07.018516Z",
     "shell.execute_reply": "2024-09-16T08:14:07.017657Z"
    },
    "papermill": {
     "duration": 0.172013,
     "end_time": "2024-09-16T08:14:07.020950",
     "exception": false,
     "start_time": "2024-09-16T08:14:06.848937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedulers = [\n",
    "    \n",
    "]\n",
    "criteria = {\n",
    "    'train': [\n",
    "        CumulativeLinkLoss(class_weights=[1,2,4]) for _ in range(CONFIG['num_classes'])\n",
    "    ],\n",
    "    'unweighted_val': [\n",
    "        CumulativeLinkLoss() for _ in range(CONFIG['num_classes'])\n",
    "    ],\n",
    "    'alt_val': [\n",
    "        nn.CrossEntropyLoss(weight=torch.Tensor([1,2,4])).to(CONFIG['device']) for _ in range(CONFIG['num_classes'])\n",
    "    ],\n",
    "    'unweighted_alt_val': [\n",
    "        nn.CrossEntropyLoss().to(device) for _ in range(CONFIG[\"num_classes\"])\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca9a12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T08:14:07.064634Z",
     "iopub.status.busy": "2024-09-16T08:14:07.064269Z",
     "iopub.status.idle": "2024-09-16T09:11:26.490746Z",
     "shell.execute_reply": "2024-09-16T09:11:26.489362Z"
    },
    "papermill": {
     "duration": 3439.441283,
     "end_time": "2024-09-16T09:11:26.493985",
     "exception": false,
     "start_time": "2024-09-16T08:14:07.052702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for index, fold in enumerate(dataset_folds):\n",
    "    model = Classifier3dMultihead(\n",
    "        backbone=CONFIG['backbone'],\n",
    "        in_chans=3, out_classes=CONFIG['num_classes']).to(\n",
    "        CONFIG['device'])\n",
    "    optimizers = [\n",
    "        torch.optim.AdamW(model.parameters(), lr=3e-4),\n",
    "    ]\n",
    "\n",
    "    trainloader, valloader, trainset, testset = fold\n",
    "\n",
    "    train_model_with_validation(model,\n",
    "                                optimizers,\n",
    "                                schedulers,\n",
    "                                criteria,\n",
    "                                trainloader,\n",
    "                                valloader,\n",
    "                                model_desc=CONFIG['backbone'] + f'_fold_{index}',\n",
    "                                train_loader_desc=f\"Training {CONFIG['backbone']} fold {index}\",\n",
    "                                epochs=CONFIG['epochs'],\n",
    "                                freeze_backbone_initial_epochs=0,\n",
    "                                callbacks=[model._ascension_callback],\n",
    "                                gradient_accumulation_per=CONFIG['gradient_acc_steps']\n",
    "                                )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    },
    {
     "modelId": 89293,
     "modelInstanceId": 64905,
     "sourceId": 114536,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3639.973903,
   "end_time": "2024-09-16T09:11:29.498598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-16T08:10:49.524695",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
